{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YX_utHD_s3h"
   },
   "source": [
    "There are four features used in this regression:\n",
    "* one binary feature (whether or not the house has covered parking)\n",
    "* one numerical feature (size, measure in thousands of square meters)\n",
    "* two categorical features (architectural style and location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1879,
     "status": "ok",
     "timestamp": 1709672078597,
     "user": {
      "displayName": "cr0wn7 cr0wn7",
      "userId": "05481356110704364561"
     },
     "user_tz": -60
    },
    "id": "7frjiXeo8p7M",
    "outputId": "27c90176-f870-46e1-b579-745a3d6f9445"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch import nn, optim, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "!gdown 1hLxbWVrnmSnZDGjvu8HeQex6ezbXeLB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1709672079338,
     "user": {
      "displayName": "cr0wn7 cr0wn7",
      "userId": "05481356110704364561"
     },
     "user_tz": -60
    },
    "id": "5xykcINg-Evc",
    "outputId": "79987922-1d8c-4758-d272-54b6dfe98c45"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "features = pd.read_csv(\n",
    "    \"house_prices.txt\",\n",
    "    delimiter = \"\\t\",\n",
    "    skiprows=[0, 1, 2, 3, 4],\n",
    "    header=None,\n",
    "    usecols=[0, 1, 2, 3, 4, 6, 7, 8],\n",
    "    names=[\"parking\", \"sq_meters\", \"art_deco\", \"bungalow\", \"colonial\", \"west\", \"east\", \"north\"],\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "target = pd.read_csv(\n",
    "    \"house_prices.txt\",\n",
    "    delimiter = \"\\t\",\n",
    "    skiprows=[0, 1, 2, 3, 4],\n",
    "    header=None,\n",
    "    usecols=[5],\n",
    "    names=[\"price\"],\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "# display the first 5 rows of the dataset\n",
    "features.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZ6wbmQXAhzR"
   },
   "source": [
    "### Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1709672079339,
     "user": {
      "displayName": "cr0wn7 cr0wn7",
      "userId": "05481356110704364561"
     },
     "user_tz": -60
    },
    "id": "zVE7qQyv4UM0",
    "outputId": "79b3b9a6-57fd-4376-8278-4fac88330e18"
   },
   "outputs": [],
   "source": [
    "def split_data(features, target, train_ratio):\n",
    "    # Determine the number of samples for training\n",
    "    num_train_samples = int(train_ratio * features.shape[0])\n",
    "\n",
    "    # Create an array of indices for shuffling\n",
    "    index = np.arange(features.shape[0])\n",
    "    np.random.shuffle(index)\n",
    "\n",
    "    # Split indices into training and testing indeces\n",
    "    train_index = index[:num_train_samples]\n",
    "    test_index = index[num_train_samples:]\n",
    "\n",
    "    # Split features and target using indices and convert to numPy-Array\n",
    "    features_train = features[train_index]\n",
    "    features_test = features[test_index]\n",
    "    target_train = target[train_index]\n",
    "    target_test = target[test_index]\n",
    "\n",
    "    return features_train, features_test, target_train, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train-ratio and split the data using the function split_data\n",
    "train_ratio = 0.8\n",
    "features_train, features_test, target_train, target_test = split_data(features.to_numpy(), target.to_numpy(), train_ratio)\n",
    "\n",
    "# create datasets\n",
    "train_features_tensor = torch.from_numpy(features_train)\n",
    "train_target_tensor = torch.from_numpy(target_train)\n",
    "\n",
    "test_features_tensor = torch.from_numpy(features_test)\n",
    "test_target_tensor = torch.from_numpy(target_test)\n",
    "\n",
    "# create datasets for training and testing\n",
    "train_dataset = utils.data.TensorDataset(train_features_tensor, train_target_tensor)\n",
    "test_dataset = utils.data.TensorDataset(test_features_tensor, test_target_tensor)\n",
    "\n",
    "# create dataloaders, batch_size = number of samples\n",
    "train_dataloader = utils.data.DataLoader(train_dataset, batch_size=40, shuffle=True)\n",
    "test_dataloader = utils.data.DataLoader(test_dataset, batch_size=40, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiMkCZAnAy-Y"
   },
   "source": [
    "### Define the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module): # inherit from the bas class\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNetwork, self).__init__() # constructor of base class\n",
    "        self.hidden1 = nn.Linear(input_size, hidden_size) # create first hidden layer\n",
    "        self.hidden2 = nn.Linear(hidden_size, hidden_size) # create second hidden layer\n",
    "        self.relu = nn.ReLU() # activation function\n",
    "        self.output_layer = nn.Linear(hidden_size, 1) # maps the hidden layers output to a single value\n",
    "\n",
    "    # input data flow trough the network\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden1(x)) # ReLU activation\n",
    "        x = self.relu(self.hidden2(x)) # ReLU activation\n",
    "        x = self.output_layer(x) # output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set training and assessment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1709672079929,
     "user": {
      "displayName": "cr0wn7 cr0wn7",
      "userId": "05481356110704364561"
     },
     "user_tz": -60
    },
    "id": "XjFqpA4o6hF_",
    "outputId": "f9911d66-45ac-4622-90dc-c6f5e87df5c9"
   },
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train_model(model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs, device):\n",
    "    train_loss_values = []\n",
    "    test_loss_values = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model in training mode\n",
    "        total_loss = 0  # Initialize total_loss\n",
    "\n",
    "        for features, targets in train_dataloader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # resetting gradients before computing new ones\n",
    "            outputs = model(features) # predictions\n",
    "            loss = criterion(outputs, targets) # calculating loss between pred and actual\n",
    "\n",
    "            loss.backward() # compute gradients of the model with respect to the loss\n",
    "            optimizer.step() # adjust model parameters (weights)\n",
    "\n",
    "            total_loss += loss.item() # apply loss to total\n",
    "\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        train_loss_values.append(avg_loss)  # Log the training loss value for this epoch\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Iteration {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Calculate test loss for each epoch but with gradient calulation disabled\n",
    "        test_loss = assess_performance(model, test_dataloader, criterion, device)\n",
    "        test_loss_values.append(test_loss)\n",
    "\n",
    "    return train_loss_values, test_loss_values\n",
    "\n",
    "\n",
    "# Define a function for performance assessment\n",
    "def assess_performance(model, dataloader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    # disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            # move to gpu\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # loss calculation\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the computing device (CPU/GPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create the model neural network\n",
    "hidden_size = 10  # number of neurons in the hidden layers\n",
    "model = NeuralNetwork(input_size=features_train.shape[1], hidden_size=hidden_size)  # input size = number of features\n",
    "model.to(device)  # Move the model to gpu or cpu\n",
    "print(model)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 300\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam optimizer\n",
    "\n",
    "# Call the training function\n",
    "train_loss_values, test_loss_values = train_model(model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# Plot the loss curves\n",
    "plt.plot(range(1, num_epochs + 1), train_loss_values, label=\"Training Loss\")\n",
    "plt.plot(range(1, num_epochs + 1), test_loss_values, label=\"Testing Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Testing Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gqu61LeEBKMO"
   },
   "source": [
    "### Performance Test using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1709672079929,
     "user": {
      "displayName": "cr0wn7 cr0wn7",
      "userId": "05481356110704364561"
     },
     "user_tz": -60
    },
    "id": "0xkt_jb-8xMU",
    "outputId": "7cf48454-6daa-4788-abd7-f8f8244d68aa"
   },
   "outputs": [],
   "source": [
    "# Calculate test loss using the assessment function \n",
    "test_loss = assess_performance(model, test_dataloader, criterion, device)\n",
    "train_loss = assess_performance(model, train_dataloader, criterion, device)\n",
    "\n",
    "# Print the calculated loss values\n",
    "print(f\"Training Loss: {train_loss:.4f}\")\n",
    "print(f\"Testing Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
